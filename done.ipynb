{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengenalan Angka Pada Aksara Sunda Menggunakan Convolutional Neural Network (CNN)\n",
    "\n",
    "Notebook ini merupakan demo dari proses pembangunan model untuk megenali angka pada aksara sunda menggunakan convolutional neural network.\n",
    "##### Hidayaturrahman (140810140050) - Universitas Padjadjaran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Mengubah data gambar ke dalam betuk biner. Kemudian dilakukan inversi pada nilainya sehingga menyederhanakan proses perhitungan. Data yang terlah diubah kemudia disimpan menjadi sebuah dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "import PIL.ImageOps as ImOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(1,16):\n",
    "\tfor j in range(1,81):\n",
    "\t\tif j < 10:\n",
    "\t\t\tfilename = \"../gambar/resized/kertas-%d_0%d.jpg\" % (i,j)\n",
    "\t\telse:\n",
    "\t\t\tfilename = \"../gambar/resized/kertas-%d_%d.jpg\" % (i,j)\n",
    "\t\timg = Image.open(filename)\n",
    "\t\tinverted_image = ImOps.invert(img)\n",
    "\t\tmatrix = np.array(inverted_image.convert('L'))\n",
    "\t\tlabel = j % 10\n",
    "\t\tif label == 0:\n",
    "\t\t\tlabel = 10\n",
    "\t\tlabel = label - 1\n",
    "\n",
    "\t\tX.append(matrix)\n",
    "\t\ty.append(label)\n",
    "\n",
    "\n",
    "data = np.array(X)\n",
    "label = np.array(y)\n",
    "\n",
    "np.savez('aksara_sunda_ip.npz', data=data, label=label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menampilkan data yang telah diolah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    plt.subplot(330+i)\n",
    "    plt.imshow(X[i+9], cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.suptitle(\"Angka pada aksara sunda\", size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Membangun Model Pertama\n",
    "Model dibangun dengan mengunnakan Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load data\n",
    "dataset = numpy.load('aksara_sunda.npz')\n",
    "X = dataset['data']\n",
    "y = dataset['label']\n",
    "\n",
    "#reshape to be [samples][width][height][chanels]\n",
    "\n",
    "X = X.reshape(X.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# X = X[0:10]\n",
    "# y = y[0:10]\n",
    "\n",
    "#normalize the data\n",
    "X = X / 255\n",
    "\n",
    "# one hot encode output\n",
    "y = np_utils.to_categorical(y)\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "def baseline_model(optimizer='adam'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(32, (6, 6), input_shape=(28, 28, 1), activation= 'relu' ))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "baseline_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melakukan Training Model Pertama\n",
    "Training dilakukan dalam 10 epoch. Training dilakukan dengan menggunakan beberapa optimizer yakni ADAM, RMSProp, SGD, Adagrad, Adadelta, Adamax, dan Nadam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### multiple optimizer\n",
    "optimizer = ['adam','rmsprop','sgd','adagrad','adadelta','adamax','nadam']\n",
    "model_acc = []\n",
    "model_loss = []\n",
    "for op in optimizer:\n",
    "\tmodel = baseline_model(op)\n",
    "\thistory = model.fit(X, y, nb_epoch=10, batch_size=1, verbose=0)\n",
    "\tmodel_acc.append(history.history['acc'])\n",
    "\tmodel_loss.append(history.history['loss'])\n",
    "\n",
    "numpy.savez('result_optimizer.npz', model_acc=model_acc, model_loss=model_loss, optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan Model Pertama\n",
    "Model disimpan dalam bentuk JSON dan bobot untuk setiap node disimpan dalam file HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "\tjson_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisasi Proses Training Model Pertama\n",
    "Visualisasi dilakukan untuk mengambarkan nilai akurasi dan loss model pada setiap iterasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = numpy.load('result_optimizer.npz')\n",
    "model_acc = data['model_acc']\n",
    "model_loss = data['model_loss']\n",
    "optimizer = data['optimizer']\n",
    "\n",
    "plt.figure(1)\n",
    "for op in range(len(optimizer)):\n",
    "\tplt.plot(model_acc[op])\n",
    "plt.title( 'model accuracy' )\n",
    "plt.ylabel( 'accuracy' )\n",
    "plt.xlabel( 'epoch' )\n",
    "plt.legend(optimizer, loc= 'best' )\n",
    "\n",
    "plt.figure(2)\n",
    "for op in range(len(optimizer)):\n",
    "\tplt.plot(model_loss[op])\n",
    "plt.title( 'model loss' )\n",
    "plt.ylabel( 'loss' )\n",
    "plt.xlabel( 'epoch' )\n",
    "plt.legend(optimizer, loc= 'best' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melakukan Evaluasi Model Pertama\n",
    "Model dievaluasi dengan melakukan k-cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ k-fold validation\n",
    "estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=10, batch_size=1, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seedt)\n",
    "result = cross_val_score(estimator, X, y, cv=kfold)\n",
    "# numpy.savez('result_kfold.npz', result=result)\n",
    "# print(result)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membangun Model Kedua\n",
    "Model dibangun dengan mengunnakan Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_model_2(optimizer='adam'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(32, (6, 6), input_shape=(28, 28, 1), activation= 'relu' ))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Convolution2D(16, (6, 6), activation= 'relu' ))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(64, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "baseline_model_2().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melakukan Training Model Kedua\n",
    "Training dilakukan dalam 10 epoch. Training dilakukan dengan menggunakan beberapa optimizer yakni ADAM, RMSProp, SGD, Adagrad, Adadelta, Adamax, dan Nadam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### multiple optimizer\n",
    "optimizer = ['adam','rmsprop','sgd','adagrad','adadelta','adamax','nadam']\n",
    "model_acc = []\n",
    "model_loss = []\n",
    "for op in optimizer:\n",
    "\tmodel = baseline_model_2(op)\n",
    "\thistory = model.fit(X, y, nb_epoch=10, batch_size=1, verbose=0)\n",
    "\tmodel_acc.append(history.history['acc'])\n",
    "\tmodel_loss.append(history.history['loss'])\n",
    "\n",
    "numpy.savez('result_optimizer_2.npz', model_acc=model_acc, model_loss=model_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan Model Kedua\n",
    "Model disimpan dalam bentuk JSON dan bobot untuk setiap node disimpan dalam file HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_2.json\", \"w\") as json_file:\n",
    "\tjson_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_2.h5\")\n",
    "print(\"Saved model_2 to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisasi Proses Training Model Kedua\n",
    "Visualisasi dilakukan untuk mengambarkan nilai akurasi dan loss model pada setiap iterasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = numpy.load('result_optimizer2.npz')\n",
    "model_acc = data['model_acc']\n",
    "model_loss = data['model_loss']\n",
    "optimizer = data['optimizer']\n",
    "\n",
    "plt.figure(1)\n",
    "for op in range(len(optimizer)):\n",
    "\tplt.plot(model_acc[op])\n",
    "plt.title( 'model accuracy' )\n",
    "plt.ylabel( 'accuracy' )\n",
    "plt.xlabel( 'epoch' )\n",
    "plt.legend(optimizer, loc= 'best' )\n",
    "\n",
    "plt.figure(2)\n",
    "for op in range(len(optimizer)):\n",
    "\tplt.plot(model_loss[op])\n",
    "plt.title( 'model loss' )\n",
    "plt.ylabel( 'loss' )\n",
    "plt.xlabel( 'epoch' )\n",
    "plt.legend(optimizer, loc= 'best' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melakukan Evaluasi Model Kedua\n",
    "Model dievaluasi dengan melakukan k-cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ k-fold validation\n",
    "estimator = KerasClassifier(build_fn=baseline_model_2, nb_epoch=10, batch_size=1, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seedt)\n",
    "result = cross_val_score(estimator, X, y, cv=kfold)\n",
    "# numpy.savez('result_kfold.npz', result=result)\n",
    "# print(result)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_book",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
